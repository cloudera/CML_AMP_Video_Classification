{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Classification\n",
    "\n",
    "Video classification is one of the many tasks in the field of _video understanding_, technologies that automatically extract information from video. You can read more about the great, wide world of video understanding in our blog post [An Introduction to Video Understanding: Capabilities and Applications](https://blog.fastforwardlabs.com/2021/12/14/an-introduction-to-video-understanding-capabilities-and-applications.html).\n",
    "\n",
    "The goal of this notebook is to provide an introduction to video classification, including datasets and models.\n",
    "The notebook consists of three main parts: \n",
    "- Setting up: Installation of the necessary packages, including Tensorflow, and importing the relevant libraries.\n",
    "- The Data: An exploration of the [Kinetics Human Action Video Dataset](https://deepmind.com/research/open-source/kinetics) for action recognition.\n",
    "- The Model: Experimentation with a pretrained version of the [I3D video classification model](https://deepmind.com/research/open-source/i3d-model) for action recognition, hosted on the Tensorflow Model Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "Install the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "#hides cell output. disable for logs.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "code",
    "id": "USf0UvkYIlKo"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make it easier to work with the dataset and model in this notebook, we created a small library of helper functions and classes. Here, we import the good bits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidbench.data.load import KineticsLoader\n",
    "from vidbench.models import I3DLoader\n",
    "from vidbench.predict import predict, store_results_in_dataframe, compute_accuracy, evaluate\n",
    "from vidbench.visualize import make_video_table\n",
    "from vidbench.data.process import resample_video, load_and_resize_video, video_acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "In this notebook we make use of the DeepMind [Kinetics dataset](https://arxiv.org/abs/1705.06950), which consists of thousands of YouTube videos focused on human actions and interactions. While there are several versions of this dataset, we'll focus primarily on the Kinetics 400 dataset which contains 400 human action classes, ranging from human-object interactions like playing instruments, as well as human-human interactions like shaking hands. Each video clip is approximately ten seconds and has been sourced from a unique YouTube video.   \n",
    "\n",
    "\n",
    "As of November 2021, the video files that make up the Kinetics datasets are stored at https://s3.amazonaws.com/kinetics/ as described in this [repository](https://github.com/cvdfoundation/kinetics-dataset). The Kinetics 400 contains a total of 306,245 video clips with at least 400 clips in each class.  These are distributed among three splits: training, test and validation. Each split consists of thousands of videos in `.mp4` format. \n",
    "\n",
    "| Dataset split | Clips per class | Total Videos |\n",
    "|---------------|-----------------|--------------|\n",
    "| train         |  250-1000       |    246245    |\n",
    "| test          |   100           |   40000      |\n",
    "| val           |     50          |   20000      |\n",
    "\n",
    "\n",
    "For each dataset split, videos are grouped into a series of directories and each directory is packaged as a `tar.gz` file that needs to be unpacked. Each of these `tar.gz` files contains about 1000 video clips.  In this notebook we'll explore a handful of videos from the validation set and we created a `KineticsLoader` class to handle downloading and unpacking these video files.  While this class is designed to handle the full validation (or test, or train) set, we can also use it to explore a small portion of the videos, which we'll demonstrate in the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to fetch, path already exists /home/cdsw/data/raw/kinetics/400/val/k400_val_path.txt\n",
      "No need to fetch, path already exists /home/cdsw/data/raw/kinetics/400/val/val.csv\n"
     ]
    }
   ],
   "source": [
    "# this class handles the infrastructure to support downloading, unpacking, and pre-processing videos\n",
    "loader = KineticsLoader(version=\"400\", split=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're exploring this notebook after performing automatic setup through the CML AMP interface, then we've already downloaded a chunk of videos to explore. If not, running the cell below will initiate a download and unpacking of (at least) 500 vidoes (recall that they are grouped in chunks of approximately 1000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.download_n_videos(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code above we've downloaded just 1000 videos from the validation set (out of 20,000 available videos). We could download the entire validation set but that would require at least 30-50 GBs of storage! Since our goal in this notebook is simply to explore the video classification capability, 1000 videos is more than enough to explore with. This AMP also includes a benchmarking script that will allow the user to evaluate a model on _all_ videos in any of the data splits discussed above (more on this towards the end of the notebook).   \n",
    "\n",
    "We've also downloaded the ground truth labels for _all_ 20K videos in the validation set. These are stored in a Pandas DataFrame which you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>split</th>\n",
       "      <th>is_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>0wR5jVB-WPk</td>\n",
       "      <td>417</td>\n",
       "      <td>427</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>3caPS4FHFF8</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>3yaoNwz99xM</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>6IbvOJxXnOo</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>6_4kjPiQr7w</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>zumba</td>\n",
       "      <td>w5hbJLVhZDI</td>\n",
       "      <td>93</td>\n",
       "      <td>103</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19902</th>\n",
       "      <td>zumba</td>\n",
       "      <td>xDd6uIBeMEA</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>zumba</td>\n",
       "      <td>XWvGn7eI04A</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19904</th>\n",
       "      <td>zumba</td>\n",
       "      <td>yGdQwxP5koA</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19905</th>\n",
       "      <td>zumba</td>\n",
       "      <td>ZVDR2od1gn8</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19906 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label   youtube_id  time_start  time_end split  is_cc\n",
       "0      abseiling  0wR5jVB-WPk         417       427   val      0\n",
       "1      abseiling  3caPS4FHFF8          36        46   val      0\n",
       "2      abseiling  3yaoNwz99xM          62        72   val      1\n",
       "3      abseiling  6IbvOJxXnOo          47        57   val      0\n",
       "4      abseiling  6_4kjPiQr7w         191       201   val      0\n",
       "...          ...          ...         ...       ...   ...    ...\n",
       "19901      zumba  w5hbJLVhZDI          93       103   val      0\n",
       "19902      zumba  xDd6uIBeMEA           1        11   val      0\n",
       "19903      zumba  XWvGn7eI04A          12        22   val      0\n",
       "19904      zumba  yGdQwxP5koA          83        93   val      0\n",
       "19905      zumba  ZVDR2od1gn8          37        47   val      0\n",
       "\n",
       "[19906 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels_df = pd.read_csv(f\"{loader.data_dir}/val.csv\")\n",
    "ground_truth_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this DataFrame has nearly 20K rows - one for each video clip in the validation set. We need to filter this DataFrame to just those videos that we've actually downloaded. Our `KineticsLoader` keeps track of which videos we've downloaded. We can see all available pathnames with the following line. We're only showing the top 20 but there are 1000 video pathnames available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/cdsw/data/raw/kinetics/400/val/part_0/0tlGOxUQ0Kw_000074_000084.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-05qSkAhM6Y_000205_000215.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-LISB_b8rIw_000049_000059.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/--ILYNHl3e4_000541_000551.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-yv8c2CDbR8_000004_000014.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-aeOuOI3eN0_000219_000229.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-WZgMWx8Elk_000013_000023.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-Y-fUYGcb7o_000049_000059.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-beyXnxwTao_000040_000050.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-whdHn9Mbcc_000000_000010.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-CAPalSW0QI_000546_000556.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/0HydDezkSU0_000018_000028.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-4hx9N2OhZo_000029_000039.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-PW6kckornM_000008_000018.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-Wx7UjNi3uU_000010_000020.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/0dwPQPV3iYQ_000039_000049.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-0r6NmrdKCU_000043_000053.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/0Lx_B0Xg3kU_000007_000017.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-5vr1M9jygc_000100_000110.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-AMpy1HyBfk_000261_000271.mp4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.video_filenames[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll filter the ground truth DataFrame to include only those vidoes that have already been downloaded and are available locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_youtube_ids = []\n",
    "for filename in loader.video_filenames:\n",
    "    pathname, vidname = os.path.split(filename)\n",
    "    available_youtube_ids.append(vidname[:11]) #youtube IDs are 11 characters long\n",
    "\n",
    "available_videos_metadata_df = ground_truth_labels_df[ground_truth_labels_df['youtube_id'].isin(available_youtube_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>split</th>\n",
       "      <th>is_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>0wR5jVB-WPk</td>\n",
       "      <td>417</td>\n",
       "      <td>427</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>air drumming</td>\n",
       "      <td>--nQbRBEz2s</td>\n",
       "      <td>104</td>\n",
       "      <td>114</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>answering questions</td>\n",
       "      <td>-egPJubR-CE</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>answering questions</td>\n",
       "      <td>-ejLPB4J4SM</td>\n",
       "      <td>106</td>\n",
       "      <td>116</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>answering questions</td>\n",
       "      <td>-emx5qjikEc</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811</th>\n",
       "      <td>yoga</td>\n",
       "      <td>-Gb1pbOE32g</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>yoga</td>\n",
       "      <td>-IeJ0CF3huY</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>yoga</td>\n",
       "      <td>-kSK2kqnTHA</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19814</th>\n",
       "      <td>yoga</td>\n",
       "      <td>0wHOYxjRmlw</td>\n",
       "      <td>41</td>\n",
       "      <td>51</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19860</th>\n",
       "      <td>zumba</td>\n",
       "      <td>0H5mnFcm2Kg</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label   youtube_id  time_start  time_end split  is_cc\n",
       "0                abseiling  0wR5jVB-WPk         417       427   val      0\n",
       "50            air drumming  --nQbRBEz2s         104       114   val      0\n",
       "99     answering questions  -egPJubR-CE           1        11   val      0\n",
       "100    answering questions  -ejLPB4J4SM         106       116   val      0\n",
       "101    answering questions  -emx5qjikEc           1        11   val      0\n",
       "...                    ...          ...         ...       ...   ...    ...\n",
       "19811                 yoga  -Gb1pbOE32g          32        42   val      0\n",
       "19812                 yoga  -IeJ0CF3huY          16        26   val      0\n",
       "19813                 yoga  -kSK2kqnTHA          22        32   val      0\n",
       "19814                 yoga  0wHOYxjRmlw          41        51   val      1\n",
       "19860                zumba  0H5mnFcm2Kg          17        27   val      0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_videos_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Now we have a DataFrame with only 1000 rows -- one for each locally available video clip. What did we end up downloading? Let's take a look at what classes we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "massaging legs             10\n",
       "scrambling eggs             9\n",
       "eating chips                8\n",
       "massaging person's head     8\n",
       "washing hair                7\n",
       "                           ..\n",
       "long jump                   1\n",
       "slacklining                 1\n",
       "marching                    1\n",
       "cleaning gutters            1\n",
       "opening present             1\n",
       "Name: label, Length: 360, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_videos_metadata_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 400 unique classes, we have videos from 360 of those. Most classes only have one representative video clip, though we do have a handful of video clips from classes like \"massaging legs,\" and \"scrambling eggs.\" \n",
    "\n",
    "Video classification is computationally expensive so in the following cell we take a small, random sample of vidoes to explore for the remainder of this notebook. Because this is a random sample, each time you run this cell you'll get a new set of 8 videos to play with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>split</th>\n",
       "      <th>is_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>smoking hookah</td>\n",
       "      <td>-0BveUV52cM</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>climbing tree</td>\n",
       "      <td>-ELsDPpCYkA</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>hugging</td>\n",
       "      <td>-FWfQhqFoYc</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19262</th>\n",
       "      <td>waxing chest</td>\n",
       "      <td>-h3LsUJLK4Y</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18164</th>\n",
       "      <td>trimming or shaving beard</td>\n",
       "      <td>-1FlCGo8M4E</td>\n",
       "      <td>574</td>\n",
       "      <td>584</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>doing nails</td>\n",
       "      <td>-5hZhtMVn9A</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>jumping into pool</td>\n",
       "      <td>-2csq_1UhMQ</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10899</th>\n",
       "      <td>playing bagpipes</td>\n",
       "      <td>-Wx7UjNi3uU</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           label   youtube_id  time_start  time_end split  \\\n",
       "15778             smoking hookah  -0BveUV52cM          43        53   val   \n",
       "3390               climbing tree  -ELsDPpCYkA           2        12   val   \n",
       "7859                     hugging  -FWfQhqFoYc          61        71   val   \n",
       "19262               waxing chest  -h3LsUJLK4Y           3        13   val   \n",
       "18164  trimming or shaving beard  -1FlCGo8M4E         574       584   val   \n",
       "4834                 doing nails  -5hZhtMVn9A          83        93   val   \n",
       "8555           jumping into pool  -2csq_1UhMQ           2        12   val   \n",
       "10899           playing bagpipes  -Wx7UjNi3uU          10        20   val   \n",
       "\n",
       "       is_cc  \n",
       "15778      0  \n",
       "3390       0  \n",
       "7859       0  \n",
       "19262      0  \n",
       "18164      0  \n",
       "4834       0  \n",
       "8555       0  \n",
       "10899      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_VIDEOS = 8\n",
    "\n",
    "video_sample = available_videos_metadata_df.sample(NUM_VIDEOS)\n",
    "video_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! We've selected a manageable batch of just 8 videos to examine. And we can see at a glance which classes our model will be attempting to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIjAyFxDZ68P"
   },
   "source": [
    "###  Visualize some videos\n",
    "\n",
    "So what kind of videos are we dealing with?  In the cell below we display our video clip sample along with their ground truth class labels. As you play each video, notice that each is only approximately ten seconds long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JTKIGevPEin5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "            <td><h2>0</h2><p>smoking hookah</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-0BveUV52cM_000043_000053.mp4\" type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>1</h2><p>climbing tree</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-ELsDPpCYkA_000002_000012.mp4\" type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>2</h2><p>hugging</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-FWfQhqFoYc_000061_000071.mp4\" type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>3</h2><p>waxing chest</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-h3LsUJLK4Y_000003_000013.mp4\" type=\"video/mp4\">\n",
       "            </video></td></tr><tr>\n",
       "            <td><h2>4</h2><p>trimming or shaving beard</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-1FlCGo8M4E_000574_000584.mp4\" type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>5</h2><p>doing nails</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-5hZhtMVn9A_000083_000093.mp4\" type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>6</h2><p>jumping into pool</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-2csq_1UhMQ_000002_000012.mp4\" type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>7</h2><p>playing bagpipes</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-Wx7UjNi3uU_000010_000020.mp4\" type=\"video/mp4\">\n",
       "            </video></td></tr><tr></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_html = make_video_table(loader.data_dir, video_sample['youtube_id'].values, video_sample['label'].values)\n",
    "display.HTML(video_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpM3SmEf7JuN"
   },
   "source": [
    "### Pre-processing\n",
    "\n",
    "Now that we have a sense of what kind of videos we're working with, let's start classifying them! But before we do that, we have another step to perform -- preprocessing.  \n",
    "\n",
    "The YouTube videos in the Kinetics dataset are all in `.mp4` format but TensorFlow models do not recognize this! We must convert the videos into a format that our TF model can work with. This requires two steps: \n",
    "1. convert the `.mp4` format to a more appropriate data structure, like NumPy arrays\n",
    "2. Resize the video dimensions to work within model specifications\n",
    "\n",
    "####  Video resizing \n",
    "While the first step is likely self-explanatory, the second step deserves some attention. Those with experience working with pre-trained image classification models are likely already familiar with the idea that these models require image inputs of a specific height and width. These requirements are determined during model training and set limits on how large (or small) an image must be in pixels in order for the model to process that image. Video classification is no different in this respect, but comes with a third dimension of complexity: time. \n",
    "\n",
    "Let's take a look at the dimensions of the videos in our sample batch. The following cells will read an `.mp4` video clip into a numpy array and print the shape of that array to the screen. The shape tuple has the following format: \n",
    "\n",
    "(number of frames, height in pixels, width in pixels, number of color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path):\n",
    "    \"\"\"Convert video to Numpy array.\"\"\"\n",
    "    import cv2\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()  # frame is in BGR format\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 720, 406, 3)\n",
      "(300, 320, 568, 3)\n",
      "(250, 720, 1280, 3)\n",
      "(300, 360, 204, 3)\n",
      "(300, 720, 1280, 3)\n",
      "(300, 720, 1280, 3)\n",
      "(300, 360, 480, 3)\n",
      "(300, 240, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "video_paths = [glob.glob(f\"{pathname}/{yt_id}*\")[0] for yt_id in video_sample['youtube_id'].values]\n",
    "\n",
    "for video_path in video_paths: \n",
    "    video_np = load_video(video_path)\n",
    "    print(video_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there's quite a bit of variation among our video batch that isn't really detectable when we viewed the raw video clips earlier. While each video is exactly 10 seconds long, some have 300 frames and others have only 127 frames. Some have small spatial dimensions (240 x 320) while others are quite large (720 x 1280). The only thing common to all videos is that they each have three color channels, the familiar RGB system. \n",
    "\n",
    "This has implications for how we sample and process these video clips for model consumption. The model we'll use in this notebook requires spatial dimensions of (224 x 224) so we'll need to resize and crop each frame of each video to these dimensions. \n",
    "\n",
    "But how do we deal with the temporal dimension, i.e., the number of frames?  That depends on how we want to use our video classification model. The model has no specified limit on the number of frames it can accept (note, however, that more frames translates to longer processing time which can become very computationally expensive!) If we only send to the model one video clip at a time, we can feed it the full number of frames for inference. However, it's usually faster to send a batch to the model rather than sending each video separately. In that case, we need to deal with the variation in frame rates for these videos because we cannot create a numpy array in which one of the dimesions varies!  \n",
    "\n",
    "#### Video Resampling\n",
    "The crux of the issue lies in the fact that different cameras have different frame capture rates. Higher quality videos have more frames-per-second (FPS) than lower quality videos leading to a situation in which a collection of 10 second videos can nevertheles have different numbers of frames. Below we show a toy example of two videos that are each 10 seconds long but the top fewer frames than the bottom one over that time span due to having a lower FPS.   \n",
    "\n",
    "![Upsampling](images/video_fps_example.jpg)\n",
    "\n",
    "In order to create a batch of video clips, we must resample the clips so that each has the same number of frames.  This can be accomplished either by _upsampling_ videos with low FPS, or _downsampling_ videos with high FPS.  A simple way to perform upsampling is to duplicate certain frames throughout the length of the video. In the figure below, we see Video 1 has frames added to match the number of frames contained in Video 2.  These frames are duplicates of existing frames in Video 1 (which is why some of the frames are repeated colors). \n",
    "\n",
    "<img src=\"images/upsample.gif\">\n",
    "\n",
    "In contrast, downsampling involves removing frames periodically throughout the video. This time, we remove a sample of unique frames from Video 2 so that it has the same number of frames as Video 1. \n",
    "<img src = \"images/downsample.gif\">\n",
    "\n",
    "In either case, resampling should be done in such a way that the frames we duplicate or remove are equally dispersed throughout the duration of the 10 second clip in order to capture as much of the original motion as possible. \n",
    "\n",
    "In a pinch we could simply grab a fixed-size chunk of consecutive frames (from the beginning, middle, or end) from each video clip. The problem here is that this chunk may only represent a portion of the full 10 second interval. The model would then attempt to infer on a batch of videos in which one of them has frames representing close to the full 10 seconds, while another has frames representing only a fraction of the time. This could increase the difficulty of the model to properly classify the latter video.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load videos into NumPy arrays\n",
    "\n",
    "Luckily, our `KineticsLoader` class has a `load_videos` method, similar to the one above, that also handles these pre-processing steps. Here's what we do under the hood:\n",
    "\n",
    "1. First, a central square proportional to the size of the video is cropped\n",
    "2. The cropped portion is resized to 224x224 pixels\n",
    "3. Videos are resampled \n",
    "   - If the user provides `num_frames`, all videos are resampled to have this many frames (upsampling those that have lower FPS, downsampling those with higher FPS)\n",
    "   - If `num_frames` is not provided, the algorithm determines which video in the batch has the lowest FPS (fewest frames) and all vidoes are downsampled to match this frame rate\n",
    "   \n",
    "\n",
    "Again we note that video clips with more total frames will take longer to process through the model. For the current dataset, `num_frames = 128` is reasonable choice.  For reference, the maximum number of frames that we've seen in the dataset is 300 (30 FPS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos(youtube_ids, num_frames):\n",
    "    \"\"\"Create numpy array with batch of videos from list of youtube ids\"\"\",\n",
    "    # we created this list of video pathnames in an earlier cell\n",
    "    global video_paths\n",
    "    \n",
    "    video_batch = []\n",
    "    for video_path in video_paths:\n",
    "        video_np = load_and_resize_video(video_path, resize_type=\"crop\")\n",
    "        video_np = np.expand_dims(video_np, axis=0)\n",
    "        video_batch.append(video_np)\n",
    "            \n",
    "    video_batch_resampled = []\n",
    "    for video in video_batch:\n",
    "        resampled_video = resample_video(video, num_frames)\n",
    "        video_batch_resampled.append(resampled_video)\n",
    "            \n",
    "    return np.concatenate(video_batch_resampled, axis=0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LbyopvjpwaTk"
   },
   "outputs": [],
   "source": [
    "num_frames = 128   \n",
    "videos_tensor = load_videos(video_sample['youtube_id'].values, num_frames=num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 128, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a batch of 8 video clips in a format that our model will understand. \n",
    "\n",
    "It's time to classify!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "In this notebook we make use of the Inflated 3D ConvNet (I3D) video classification model. This model architecture was introduced in 2017 and provided state-of-the-art results for video action classification for multiple datasets. You can read more about this model in the original paper, [Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset](https://arxiv.org/abs/1705.07750). \n",
    "\n",
    "Since it's inception, there are now multiple pre-trained versions of the I3D model that are publicly available on the [TensorFlow Model Hub](https://www.tensorflow.org/hub). The original version was pre-trained on the Kinetics 400 dataset, which we explored above. Another version was trained on the Kinetics 600 dataset. We created an `I3DLoader` class to handle model loading from the TF Model Hub. You can choose either the `kinetics-400` or `kinetics-600` version. \n",
    "\n",
    "The biggest difference between these two models is in the number of classes they predict. I3D trained on Kinetics 400 predicts, you guessed it, 400 different classes, while it's counterpart (I3D trained on Kinetics 600) predicts on 600 classes. While we didn't discuss the Kinetics 600 dataset in detail, it is essentially a superset of the Kinetics 400 dataset -- it includes all 400 labels from that dataset, plus an additional 200 unique classes. Either can be used to make inference on our sample of videos but keep in mind that with more classes comes more challenges in predicting the correct class -- there are simply more options for the model to choose from. \n",
    "\n",
    "Below we load up the I3D model trained on the Kinetics 400 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mYei3gz4D-1O"
   },
   "outputs": [],
   "source": [
    "i3d400 = I3DLoader(trained_on='kinetics-400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what kinds of predictions this model can make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abseiling',\n",
       " 'air drumming',\n",
       " 'answering questions',\n",
       " 'applauding',\n",
       " 'applying cream',\n",
       " 'archery',\n",
       " 'arm wrestling',\n",
       " 'arranging flowers',\n",
       " 'assembling computer',\n",
       " 'auctioning',\n",
       " 'baby waking up',\n",
       " 'baking cookies',\n",
       " 'balloon blowing',\n",
       " 'bandaging',\n",
       " 'barbequing',\n",
       " 'bartending',\n",
       " 'beatboxing',\n",
       " 'bee keeping',\n",
       " 'belly dancing',\n",
       " 'bench pressing']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i3d400.labels[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model predictions\n",
    "\n",
    "Now that we have data in the proper format, ground truth labels, and a model loaded and ready to go -- it's time to make predictions! This notebook was developed on CPUs so the following cell can take some time to run. One way to speed up inference is to resample the vidoes to each have fewer frames, as we discussed above. The downside is that performance will likely degrade since the model will have fewer frames on which to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eRCresdXShW3"
   },
   "outputs": [],
   "source": [
    "scores, predictions, _, _ = predict(videos_tensor, i3d400, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of our `predict` function includes the probabilities associated with each of the 400 labels and the 400 labels themselves for each video clip in our batch, sorted in descending order so that the most likely classes (highest probabilities) are at the top of the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['playing harmonica', 'eating hotdog', 'eating burger', ...,\n",
       "        'skiing crosscountry', 'skiing slalom', 'riding mule'],\n",
       "       ['rock climbing', 'climbing a rope', 'climbing tree', ...,\n",
       "        'playing controller', 'building cabinet', 'tapping pen'],\n",
       "       ['headbutting', 'slapping', 'pumping fist', ...,\n",
       "        'breading or breadcrumbing', 'paragliding', 'golf chipping'],\n",
       "       ...,\n",
       "       ['washing hands', 'doing nails', 'making a cake', ...,\n",
       "        'trapezing', 'shearing sheep', 'riding mule'],\n",
       "       ['jumping into pool', 'somersaulting', 'springboard diving', ...,\n",
       "        'making sushi', 'sharpening knives', 'getting a tattoo'],\n",
       "       ['playing bagpipes', 'singing', 'paragliding', ...,\n",
       "        'dribbling basketball', 'water sliding',\n",
       "        'catching or throwing softball']], dtype='<U39')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.86612219e-01, 1.76524267e-01, 1.00085415e-01, ...,\n",
       "        1.80657391e-08, 1.39200260e-08, 1.12994956e-08],\n",
       "       [6.39056742e-01, 1.96823344e-01, 1.34719953e-01, ...,\n",
       "        6.79193767e-12, 5.81971060e-12, 3.76654307e-12],\n",
       "       [3.28819394e-01, 1.41055599e-01, 6.81093484e-02, ...,\n",
       "        1.54618149e-07, 1.00298585e-07, 1.00217790e-07],\n",
       "       ...,\n",
       "       [2.26052657e-01, 2.09268406e-01, 1.23839580e-01, ...,\n",
       "        7.19659166e-10, 6.01304562e-10, 4.23864638e-10],\n",
       "       [8.40871334e-01, 7.77837187e-02, 4.24317531e-02, ...,\n",
       "        4.25292288e-13, 3.77804206e-13, 3.25946111e-13],\n",
       "       [9.98535514e-01, 1.07667851e-03, 1.44116653e-04, ...,\n",
       "        1.79997996e-11, 1.42494471e-11, 3.49846389e-12]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store our results as a Pandas DataFrame to make it easier to work with. This dataframe keeps only the top five model predictions for each video. The `Video_Id` index refers to the numbering of the vidoes in our visualize section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rG2INvv6TjpY"
   },
   "outputs": [],
   "source": [
    "# collect metadata and model results\n",
    "results = defaultdict(list)\n",
    "\n",
    "results['YouTube_Id'] = video_sample['youtube_id'].values\n",
    "results['Ground_Truth'] = video_sample['label'].values\n",
    "\n",
    "for s, p in zip(scores, predictions):\n",
    "    results['scores'].append(list(s[:5]))\n",
    "    results['preds'].append(list(p[:5]))\n",
    "\n",
    "results_df = store_results_in_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YouTube_Id</th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0BveUV52cM</td>\n",
       "      <td>smoking hookah</td>\n",
       "      <td>playing harmonica</td>\n",
       "      <td>eating hotdog</td>\n",
       "      <td>eating burger</td>\n",
       "      <td>playing poker</td>\n",
       "      <td>smoking</td>\n",
       "      <td>0.186612</td>\n",
       "      <td>0.176524</td>\n",
       "      <td>0.100085</td>\n",
       "      <td>8.874860e-02</td>\n",
       "      <td>4.868247e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-ELsDPpCYkA</td>\n",
       "      <td>climbing tree</td>\n",
       "      <td>rock climbing</td>\n",
       "      <td>climbing a rope</td>\n",
       "      <td>climbing tree</td>\n",
       "      <td>abseiling</td>\n",
       "      <td>pull ups</td>\n",
       "      <td>0.639057</td>\n",
       "      <td>0.196823</td>\n",
       "      <td>0.134720</td>\n",
       "      <td>1.998034e-02</td>\n",
       "      <td>2.606250e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-FWfQhqFoYc</td>\n",
       "      <td>hugging</td>\n",
       "      <td>headbutting</td>\n",
       "      <td>slapping</td>\n",
       "      <td>pumping fist</td>\n",
       "      <td>hugging</td>\n",
       "      <td>kissing</td>\n",
       "      <td>0.328819</td>\n",
       "      <td>0.141056</td>\n",
       "      <td>0.068109</td>\n",
       "      <td>6.260131e-02</td>\n",
       "      <td>4.924914e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-h3LsUJLK4Y</td>\n",
       "      <td>waxing chest</td>\n",
       "      <td>waxing chest</td>\n",
       "      <td>waxing legs</td>\n",
       "      <td>waxing back</td>\n",
       "      <td>shaving legs</td>\n",
       "      <td>tickling</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.191966e-07</td>\n",
       "      <td>1.845836e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1FlCGo8M4E</td>\n",
       "      <td>trimming or shaving beard</td>\n",
       "      <td>trimming or shaving beard</td>\n",
       "      <td>brush painting</td>\n",
       "      <td>brushing teeth</td>\n",
       "      <td>shaving head</td>\n",
       "      <td>doing nails</td>\n",
       "      <td>0.686045</td>\n",
       "      <td>0.241118</td>\n",
       "      <td>0.017078</td>\n",
       "      <td>1.634330e-02</td>\n",
       "      <td>7.074527e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5hZhtMVn9A</td>\n",
       "      <td>doing nails</td>\n",
       "      <td>washing hands</td>\n",
       "      <td>doing nails</td>\n",
       "      <td>making a cake</td>\n",
       "      <td>applying cream</td>\n",
       "      <td>cleaning shoes</td>\n",
       "      <td>0.226053</td>\n",
       "      <td>0.209268</td>\n",
       "      <td>0.123840</td>\n",
       "      <td>1.200006e-01</td>\n",
       "      <td>8.733294e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2csq_1UhMQ</td>\n",
       "      <td>jumping into pool</td>\n",
       "      <td>jumping into pool</td>\n",
       "      <td>somersaulting</td>\n",
       "      <td>springboard diving</td>\n",
       "      <td>swimming butterfly stroke</td>\n",
       "      <td>cartwheeling</td>\n",
       "      <td>0.840871</td>\n",
       "      <td>0.077784</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>1.513089e-02</td>\n",
       "      <td>1.438927e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-Wx7UjNi3uU</td>\n",
       "      <td>playing bagpipes</td>\n",
       "      <td>playing bagpipes</td>\n",
       "      <td>singing</td>\n",
       "      <td>paragliding</td>\n",
       "      <td>playing clarinet</td>\n",
       "      <td>playing saxophone</td>\n",
       "      <td>0.998536</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>7.023879e-05</td>\n",
       "      <td>4.132017e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           YouTube_Id               Ground_Truth                     pred_1  \\\n",
       "video_id                                                                      \n",
       "0         -0BveUV52cM             smoking hookah          playing harmonica   \n",
       "1         -ELsDPpCYkA              climbing tree              rock climbing   \n",
       "2         -FWfQhqFoYc                    hugging                headbutting   \n",
       "3         -h3LsUJLK4Y               waxing chest               waxing chest   \n",
       "4         -1FlCGo8M4E  trimming or shaving beard  trimming or shaving beard   \n",
       "5         -5hZhtMVn9A                doing nails              washing hands   \n",
       "6         -2csq_1UhMQ          jumping into pool          jumping into pool   \n",
       "7         -Wx7UjNi3uU           playing bagpipes           playing bagpipes   \n",
       "\n",
       "                   pred_2              pred_3                     pred_4  \\\n",
       "video_id                                                                   \n",
       "0           eating hotdog       eating burger              playing poker   \n",
       "1         climbing a rope       climbing tree                  abseiling   \n",
       "2                slapping        pumping fist                    hugging   \n",
       "3             waxing legs         waxing back               shaving legs   \n",
       "4          brush painting      brushing teeth               shaving head   \n",
       "5             doing nails       making a cake             applying cream   \n",
       "6           somersaulting  springboard diving  swimming butterfly stroke   \n",
       "7                 singing         paragliding           playing clarinet   \n",
       "\n",
       "                     pred_5   score_1   score_2   score_3       score_4  \\\n",
       "video_id                                                                  \n",
       "0                   smoking  0.186612  0.176524  0.100085  8.874860e-02   \n",
       "1                  pull ups  0.639057  0.196823  0.134720  1.998034e-02   \n",
       "2                   kissing  0.328819  0.141056  0.068109  6.260131e-02   \n",
       "3                  tickling  0.999979  0.000016  0.000004  2.191966e-07   \n",
       "4               doing nails  0.686045  0.241118  0.017078  1.634330e-02   \n",
       "5            cleaning shoes  0.226053  0.209268  0.123840  1.200006e-01   \n",
       "6              cartwheeling  0.840871  0.077784  0.042432  1.513089e-02   \n",
       "7         playing saxophone  0.998536  0.001077  0.000144  7.023879e-05   \n",
       "\n",
       "               score_5  \n",
       "video_id                \n",
       "0         4.868247e-02  \n",
       "1         2.606250e-03  \n",
       "2         4.924914e-02  \n",
       "3         1.845836e-07  \n",
       "4         7.074527e-03  \n",
       "5         8.733294e-02  \n",
       "6         1.438927e-02  \n",
       "7         4.132017e-05  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "So how well did our model do?  It may seem natural to consider the model's accuracy using only it's top prediction for each video and we'll look at that first. However, when working with hundreds of classes, subtlties arise. For example, some classes could be easily confused -- \"catching or throwing a softball\" and \"catching or throwing a baseball\" are both classes but it may be difficult for the model to discern the type of ball in a low quality video or if the ball only takes up a small handful of pixels in a wide-shot video.  Additionaly, videos can contain more than one action -- \"texting\" while \"driving a car\" (don't do that!) or \"hula hooping\" while \"playing ukulele\". The Kinetics 400 dataset only provides a single ground-truth label for each video, rather than an exhaustive list of annotations. For this reason, the authors recommend evaluating model performance on the top-5 accuracy, rather than top-1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize videos again\n",
    "\n",
    "Let's first examine the model's top-1 accuracy by considering our video visualization. Our visualization helper function can also accept and display the model's top prediction beneath each video. If the model's prediction does not match the ground truth label, the text will display red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "            <td><h2>0</h2><p>smoking hookah</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-0BveUV52cM_000043_000053.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>playing harmonica</p></td>\n",
       "            <td><h2>1</h2><p>climbing tree</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-ELsDPpCYkA_000002_000012.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>rock climbing</p></td>\n",
       "            <td><h2>2</h2><p>hugging</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-FWfQhqFoYc_000061_000071.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>headbutting</p></td>\n",
       "            <td><h2>3</h2><p>waxing chest</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-h3LsUJLK4Y_000003_000013.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>waxing chest</p></td></tr><tr>\n",
       "            <td><h2>4</h2><p>trimming or shaving beard</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-1FlCGo8M4E_000574_000584.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>trimming or shaving beard</p></td>\n",
       "            <td><h2>5</h2><p>doing nails</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-5hZhtMVn9A_000083_000093.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>washing hands</p></td>\n",
       "            <td><h2>6</h2><p>jumping into pool</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-2csq_1UhMQ_000002_000012.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>jumping into pool</p></td>\n",
       "            <td><h2>7</h2><p>playing bagpipes</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=\"data/raw/kinetics/400/val/part_0/-Wx7UjNi3uU_000010_000020.mp4\" type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>playing bagpipes</p></td></tr><tr></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_html = make_video_table(loader.data_dir, results_df['YouTube_Id'], results_df['Ground_Truth'], results_df['pred_1'])\n",
    "display.HTML(video_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it may seem alarming that many of these texts are red, consider them in light of the discussion above -- how many of these top-1 labels might be a reasonable description of the video clip, even if it doesn't match the ground truth label? Are any of these labels possible points of confusion or are their multiple actions in the scene? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy on our very small sample\n",
    "\n",
    "Finally, let's consider the top-5 accuracy. In this case, we score the model as being \"correct\" if the ground truth label is within the model's top-5 predictions for a given video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-FHr8nDVl_9j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1 accuracy: 50.00%\n",
      "top-5 accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "accuracy_top_1 = compute_accuracy(results_df, num_top_classes = 1)\n",
    "accuracy_top_5 = compute_accuracy(results_df, num_top_classes = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model's accuracy improves when we consider the top-5 predictions. While this approach doesn't always make sense for every circumstance, due to the nature of the Kinetics dataset and it's annotations, this method is certainly valid in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating over many videos\n",
    "\n",
    "So far, everything we've done has been to explore the capability of video classification with a small, concrete example. However, in practice, there are several models and many datasets that one might consider when building a real-world video classification application. In that case, one will need to evaluate dfferent models over various datasets in order to gauge which is most appropriate for the application in question. This is a model benchmarking job. To that end, we've created some additional utilities to facilitate model evaluation over a much larger portion of the Kinetics datasets. Included in this AMP is a benchmarking script that can be automated via the CML Jobs abstraction (or by a simple bash script, if that's your style). Here we provide a quick example of the core utilities contained within that script -- namely, the ability to load, pre-process, and batch over a larger portion of videos. \n",
    "\n",
    "We break this task into two parts: load and cache videos, and evaluation. The first step is performed by our `KineticsLoader` class, and does essentially the same steps as our `load_videos` function above. Specifically, this will load the raw `mp4` format into numpy arrays and perform essential pre-processing, such as cropping and resizing to I3D specifications. Once loaded, these video examples are cached (saved to disk) in their numpy format so that they can be reused in any downstream evaluation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0tlGOxUQ0Kw_000074_000084.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-05qSkAhM6Y_000205_000215.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-LISB_b8rIw_000049_000059.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/--ILYNHl3e4_000541_000551.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-yv8c2CDbR8_000004_000014.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-aeOuOI3eN0_000219_000229.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-WZgMWx8Elk_000013_000023.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-Y-fUYGcb7o_000049_000059.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-beyXnxwTao_000040_000050.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-whdHn9Mbcc_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-CAPalSW0QI_000546_000556.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0HydDezkSU0_000018_000028.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-4hx9N2OhZo_000029_000039.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-PW6kckornM_000008_000018.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-Wx7UjNi3uU_000010_000020.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0dwPQPV3iYQ_000039_000049.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-0r6NmrdKCU_000043_000053.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0Lx_B0Xg3kU_000007_000017.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-5vr1M9jygc_000100_000110.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-AMpy1HyBfk_000261_000271.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-mhWqo41duA_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-sf01vs2YMg_000146_000156.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/00cwEcZZcu4_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-4JdZpx3zNk_000268_000278.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0d2XdZRy2fc_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/16nvBqBrrL0_000025_000035.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-C38_1dMytQ_000027_000037.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-RE0Mjs6Hdw_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0mX7eiHEiP8_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-9V1qe3Lk2M_000001_000011.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0N8szFGAmMw_000412_000422.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-W3DfTD7kYY_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-vxNdkgPqzg_000033_000043.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/018EClOtVTM_000035_000045.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-jPhOjjHIl0_000176_000186.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-bVVs-_nntQ_000056_000066.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-ApPJCMjZVg_000114_000124.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-owlUWS7Sds_000086_000096.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-1Hub6Ps_cc_000047_000057.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/031AhY-44lw_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0C6viKYd1B4_000051_000061.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-i1c-6xhoWk_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/--AbCB6WSN0_000018_000028.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0xAB67W5GS4_000969_000979.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0yNXOIqJLtA_000012_000022.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-5klnjYyA6o_000002_000012.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-INebMIVKyo_000005_000015.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-2csq_1UhMQ_000002_000012.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-02UO1KSdZ0_000025_000035.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-khmO1mLnoA_000143_000153.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/1-Gu8XdbVl8_000071_000081.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/--oJV4vFNeI_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-DtqvvSHdk4_000076_000086.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-kFCALWZ8dQ_000007_000017.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-2C-yeMmge0_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-5LEMasZdOc_000015_000025.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-UaSZJopmBk_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-DavtY9xgnc_000545_000555.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-3Ck7V6iqPk_000008_000018.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-dSUldceBAA_000031_000041.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0Xt8zQ_UPq8_000026_000036.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-_hu_Ld-ddk_000007_000017.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/13Ub1MDkiHc_000014_000024.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-1QTRLQSzhQ_000145_000155.mp4\n"
     ]
    }
   ],
   "source": [
    "num_videos = 64\n",
    "loader.load_and_cache_video_examples(num_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is an evaluation function that encapsulates all of the prediction steps we performed above. This function accepts a model and data loader class and infers on the requested number of videos, grouping them into the given `batch_size` after resampling to `num_frames` number of frames for each video. The results are stored in a Pandas DataFrame so that we can consider the overall model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = evaluate(\n",
    "    i3d400,\n",
    "    loader, \n",
    "    num_videos=num_videos, \n",
    "    batch_size=8, \n",
    "    top_n_results=5, \n",
    "    num_frames=100, \n",
    "    savefile=\"small_sample_results_i3d.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YouTube_Id</th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1Hub6Ps_cc</td>\n",
       "      <td>washing hands</td>\n",
       "      <td>washing hands</td>\n",
       "      <td>washing hair</td>\n",
       "      <td>washing dishes</td>\n",
       "      <td>taking a shower</td>\n",
       "      <td>shaving legs</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>7.551486e-07</td>\n",
       "      <td>5.958571e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-LISB_b8rIw</td>\n",
       "      <td>making sushi</td>\n",
       "      <td>arranging flowers</td>\n",
       "      <td>opening present</td>\n",
       "      <td>setting table</td>\n",
       "      <td>wrapping present</td>\n",
       "      <td>eating spaghetti</td>\n",
       "      <td>0.169844</td>\n",
       "      <td>0.110486</td>\n",
       "      <td>0.062749</td>\n",
       "      <td>4.887363e-02</td>\n",
       "      <td>3.537429e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0r6NmrdKCU</td>\n",
       "      <td>making tea</td>\n",
       "      <td>making tea</td>\n",
       "      <td>setting table</td>\n",
       "      <td>cleaning toilet</td>\n",
       "      <td>making a cake</td>\n",
       "      <td>shredding paper</td>\n",
       "      <td>0.527350</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>6.867204e-02</td>\n",
       "      <td>3.120951e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-CAPalSW0QI</td>\n",
       "      <td>arranging flowers</td>\n",
       "      <td>arranging flowers</td>\n",
       "      <td>setting table</td>\n",
       "      <td>decorating the christmas tree</td>\n",
       "      <td>folding napkins</td>\n",
       "      <td>cleaning windows</td>\n",
       "      <td>0.995011</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>1.811463e-04</td>\n",
       "      <td>1.031628e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--ILYNHl3e4</td>\n",
       "      <td>digging</td>\n",
       "      <td>reading newspaper</td>\n",
       "      <td>skiing (not slalom or crosscountry)</td>\n",
       "      <td>skiing slalom</td>\n",
       "      <td>writing</td>\n",
       "      <td>skiing crosscountry</td>\n",
       "      <td>0.266331</td>\n",
       "      <td>0.127142</td>\n",
       "      <td>0.117140</td>\n",
       "      <td>1.019598e-01</td>\n",
       "      <td>7.865583e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0xAB67W5GS4</td>\n",
       "      <td>scuba diving</td>\n",
       "      <td>cleaning windows</td>\n",
       "      <td>pumping gas</td>\n",
       "      <td>blasting sand</td>\n",
       "      <td>taking a shower</td>\n",
       "      <td>scuba diving</td>\n",
       "      <td>0.146501</td>\n",
       "      <td>0.103552</td>\n",
       "      <td>0.076591</td>\n",
       "      <td>7.604447e-02</td>\n",
       "      <td>4.983969e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-aeOuOI3eN0</td>\n",
       "      <td>cutting nails</td>\n",
       "      <td>bandaging</td>\n",
       "      <td>waxing legs</td>\n",
       "      <td>somersaulting</td>\n",
       "      <td>washing feet</td>\n",
       "      <td>cleaning shoes</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0.035430</td>\n",
       "      <td>0.028659</td>\n",
       "      <td>2.356781e-02</td>\n",
       "      <td>2.087780e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>018EClOtVTM</td>\n",
       "      <td>situp</td>\n",
       "      <td>situp</td>\n",
       "      <td>exercising with an exercise ball</td>\n",
       "      <td>exercising arm</td>\n",
       "      <td>throwing ball</td>\n",
       "      <td>stretching arm</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>5.420654e-05</td>\n",
       "      <td>1.453274e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-_hu_Ld-ddk</td>\n",
       "      <td>peeling potatoes</td>\n",
       "      <td>clay pottery making</td>\n",
       "      <td>washing hands</td>\n",
       "      <td>making tea</td>\n",
       "      <td>rock scissors paper</td>\n",
       "      <td>peeling potatoes</td>\n",
       "      <td>0.625126</td>\n",
       "      <td>0.129556</td>\n",
       "      <td>0.057470</td>\n",
       "      <td>5.311957e-02</td>\n",
       "      <td>2.710894e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-W3DfTD7kYY</td>\n",
       "      <td>kicking field goal</td>\n",
       "      <td>kicking field goal</td>\n",
       "      <td>high kick</td>\n",
       "      <td>shooting goal (soccer)</td>\n",
       "      <td>passing American football (not in game)</td>\n",
       "      <td>kicking soccer ball</td>\n",
       "      <td>0.974316</td>\n",
       "      <td>0.014338</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>2.121597e-03</td>\n",
       "      <td>1.595268e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           YouTube_Id        Ground_Truth               pred_1  \\\n",
       "video_id                                                         \n",
       "0         -1Hub6Ps_cc       washing hands        washing hands   \n",
       "1         -LISB_b8rIw        making sushi    arranging flowers   \n",
       "2         -0r6NmrdKCU          making tea           making tea   \n",
       "3         -CAPalSW0QI   arranging flowers    arranging flowers   \n",
       "4         --ILYNHl3e4             digging    reading newspaper   \n",
       "...               ...                 ...                  ...   \n",
       "59        0xAB67W5GS4        scuba diving     cleaning windows   \n",
       "60        -aeOuOI3eN0       cutting nails            bandaging   \n",
       "61        018EClOtVTM               situp                situp   \n",
       "62        -_hu_Ld-ddk    peeling potatoes  clay pottery making   \n",
       "63        -W3DfTD7kYY  kicking field goal   kicking field goal   \n",
       "\n",
       "                                       pred_2                         pred_3  \\\n",
       "video_id                                                                       \n",
       "0                                washing hair                 washing dishes   \n",
       "1                             opening present                  setting table   \n",
       "2                               setting table                cleaning toilet   \n",
       "3                               setting table  decorating the christmas tree   \n",
       "4         skiing (not slalom or crosscountry)                  skiing slalom   \n",
       "...                                       ...                            ...   \n",
       "59                                pumping gas                  blasting sand   \n",
       "60                                waxing legs                  somersaulting   \n",
       "61           exercising with an exercise ball                 exercising arm   \n",
       "62                              washing hands                     making tea   \n",
       "63                                  high kick         shooting goal (soccer)   \n",
       "\n",
       "                                           pred_4               pred_5  \\\n",
       "video_id                                                                 \n",
       "0                                 taking a shower         shaving legs   \n",
       "1                                wrapping present     eating spaghetti   \n",
       "2                                   making a cake      shredding paper   \n",
       "3                                 folding napkins     cleaning windows   \n",
       "4                                         writing  skiing crosscountry   \n",
       "...                                           ...                  ...   \n",
       "59                                taking a shower         scuba diving   \n",
       "60                                   washing feet       cleaning shoes   \n",
       "61                                  throwing ball       stretching arm   \n",
       "62                            rock scissors paper     peeling potatoes   \n",
       "63        passing American football (not in game)  kicking soccer ball   \n",
       "\n",
       "           score_1   score_2   score_3       score_4       score_5  \n",
       "video_id                                                            \n",
       "0         0.999894  0.000098  0.000007  7.551486e-07  5.958571e-07  \n",
       "1         0.169844  0.110486  0.062749  4.887363e-02  3.537429e-02  \n",
       "2         0.527350  0.123318  0.079832  6.867204e-02  3.120951e-02  \n",
       "3         0.995011  0.004133  0.000237  1.811463e-04  1.031628e-04  \n",
       "4         0.266331  0.127142  0.117140  1.019598e-01  7.865583e-02  \n",
       "...            ...       ...       ...           ...           ...  \n",
       "59        0.146501  0.103552  0.076591  7.604447e-02  4.983969e-02  \n",
       "60        0.039472  0.035430  0.028659  2.356781e-02  2.087780e-02  \n",
       "61        0.999537  0.000294  0.000083  5.420654e-05  1.453274e-05  \n",
       "62        0.625126  0.129556  0.057470  5.311957e-02  2.710894e-02  \n",
       "63        0.974316  0.014338  0.005685  2.121597e-03  1.595268e-03  \n",
       "\n",
       "[64 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1 accuracy: 56.25%\n",
      "top-5 accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy_top_1 = compute_accuracy(results_df, num_top_classes = 1)\n",
    "accuracy_top_5 = compute_accuracy(results_df, num_top_classes = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform evaluation on larger datasets, please check [scripts/evaluate.py](scripts/evaluate.py). Instructions can be found in the [scripts/README.md](README.md) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If this documentation includes code, including but not limited to, code examples, Cloudera makes this available to you under the terms of the Apache License, Version 2.0, including any required notices. A copy of the Apache License Version 2.0 can be found here.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "x8Q7Un821X1A"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "tf_action_recognition_UCF101_DAN",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
